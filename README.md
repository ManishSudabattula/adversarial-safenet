# Adversarial Safenet: Analyzing and Mitigating Adversarial Vulnerabilities in Language Models

> ğŸ“ University of South Florida  
> ğŸ§‘â€ğŸ’» Authors: Rushitha Alva, Manish Sudabattula  
> ğŸ“„ Final Project - Natural Language Processing (Spring 2025)

## ğŸ” Project Overview

This repository contains the implementation of **Adversarial Safenet**, a framework designed to identify and mitigate adversarial vulnerabilities in fine-tuned large language models (LLMs) such as GPT-2.

The project integrates:
- **Adversarial Testing** using [AdvPrompter](https://arxiv.org/abs/2303.00000)
- **Influence Analysis** with [TracInCP](https://arxiv.org/abs/2002.08484)
- **Iterative Dataset Refinement** for reducing harmful outputs

Our goal is to make LLMs safer and more aligned by understanding how specific training samples influence harmful outputs.

---

## ğŸ§  Core Techniques

### 1. Fine-Tuning GPT-2
- Dataset: WikiHow (preprocessed and tokenized)
- Framework: Hugging Face Transformers
- Objective: Align model behavior with harmless, instructive responses

### 2. Adversarial Prompt Generation
- Tool: AdvPrompter
- Purpose: Stress-test the model using crafted suffixes that elicit unsafe or biased outputs

### 3. Influence Analysis
- Tool: TracInCP (Captum)
- Objective: Trace harmful outputs back to specific training examples using gradient-based influence scores

---

## ğŸ§ª Results

- ğŸ” **Jailbreaking Success Rate**: Dropped from 35.4% to 20.3% after iterative refinement  
- âš–ï¸ **Model Fluency**: Maintained with stable perplexity scores  
- ğŸ” **Top Influential Samples**: Identified and visualized based on impact

---

## ğŸ“ Repository Structure

```bash
.
â”œâ”€â”€ tracin.ipynb               # Main notebook for influence tracing and analysis
â”œâ”€â”€ foo.csv                    # Adversarial prompts generated by AdvPrompter
â”œâ”€â”€ README.md                  # You're here
â”œâ”€â”€ checkpoints/               # Fine-tuned GPT-2 model checkpoints
â””â”€â”€ data/
    â”œâ”€â”€ train_624.csv          # Refined training data
    â””â”€â”€ validation_624.csv     # Refined validation data
```

---

## ğŸš€ Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/your-username/adversarial-safenet.git
cd adversarial-safenet
```

### 2. Set up the environment
```bash
pip install -r requirements.txt
```

### 3. Run the notebook
Open `tracin.ipynb` in Jupyter or Colab to start influence tracing and evaluation.

---

## ğŸ“š References

- [AdvPrompter: Yang et al., 2023](https://arxiv.org/abs/2303.00000)
- [TracIn: Pruthi et al., 2020](https://arxiv.org/abs/2002.08484)
- [Hugging Face Transformers](https://huggingface.co)
- [Captum Library](https://captum.ai)
- [WikiHow Dataset](https://arxiv.org/abs/1810.09305)

---

## ğŸ“„ Report

Full report:  
ğŸ“ [Adversarial-safenet.pdf](./Adversarial-safenet.pdf)

---

## ğŸ™ Acknowledgments

Special thanks to **Professor Anshuman Chabbra** for the mentorship, and the open-source community behind Hugging Face, Captum, and PyTorch for their incredible tools.

---

## ğŸ›¡ï¸ License

This project is for academic and research purposes only. Please cite appropriately if reused.
