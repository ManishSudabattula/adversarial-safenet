# Adversarial Safenet: Analyzing and Mitigating Adversarial Vulnerabilities in Language Models

> 📍 University of South Florida  
> 🧑‍💻 Authors: Rushitha Alva, Manish Sudabattula  
> 📄 Final Project - Natural Language Processing (Spring 2025)

## 🔍 Project Overview

This repository contains the implementation of **Adversarial Safenet**, a framework designed to identify and mitigate adversarial vulnerabilities in fine-tuned large language models (LLMs) such as GPT-2.

The project integrates:
- **Adversarial Testing** using [AdvPrompter](https://arxiv.org/abs/2303.00000)
- **Influence Analysis** with [TracInCP](https://arxiv.org/abs/2002.08484)
- **Iterative Dataset Refinement** for reducing harmful outputs

Our goal is to make LLMs safer and more aligned by understanding how specific training samples influence harmful outputs.

---

## 🧠 Core Techniques

### 1. Fine-Tuning GPT-2
- Dataset: WikiHow (preprocessed and tokenized)
- Framework: Hugging Face Transformers
- Objective: Align model behavior with harmless, instructive responses

### 2. Adversarial Prompt Generation
- Tool: AdvPrompter
- Purpose: Stress-test the model using crafted suffixes that elicit unsafe or biased outputs

### 3. Influence Analysis
- Tool: TracInCP (Captum)
- Objective: Trace harmful outputs back to specific training examples using gradient-based influence scores

---

## 🧪 Results

- 🔐 **Jailbreaking Success Rate**: Dropped from 35.4% to 20.3% after iterative refinement  
- ⚖️ **Model Fluency**: Maintained with stable perplexity scores  
- 🔍 **Top Influential Samples**: Identified and visualized based on impact

---

## 📁 Repository Structure

```bash
.
├── tracin.ipynb               # Main notebook for influence tracing and analysis
├── foo.csv                    # Adversarial prompts generated by AdvPrompter
├── README.md                  # You're here
├── checkpoints/               # Fine-tuned GPT-2 model checkpoints
└── data/
    ├── train_624.csv          # Refined training data
    └── validation_624.csv     # Refined validation data
```

---

## 🚀 Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/your-username/adversarial-safenet.git
cd adversarial-safenet
```

### 2. Set up the environment
```bash
pip install -r requirements.txt
```

### 3. Run the notebook
Open `tracin.ipynb` in Jupyter or Colab to start influence tracing and evaluation.

---

## 📚 References

- [AdvPrompter: Yang et al., 2023](https://arxiv.org/abs/2303.00000)
- [TracIn: Pruthi et al., 2020](https://arxiv.org/abs/2002.08484)
- [Hugging Face Transformers](https://huggingface.co)
- [Captum Library](https://captum.ai)
- [WikiHow Dataset](https://arxiv.org/abs/1810.09305)

---

## 📄 Report

Full report:  
📎 [Adversarial-safenet.pdf](./Adversarial-safenet.pdf)

---

## 🙏 Acknowledgments

Special thanks to **Professor Anshuman Chabbra** for the mentorship, and the open-source community behind Hugging Face, Captum, and PyTorch for their incredible tools.

---

## 🛡️ License

This project is for academic and research purposes only. Please cite appropriately if reused.
